{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go thoroughly through the attached research paper. i have taken a dataset where it has only images and labeled 0 for real and 1 for fake (labels.csv). \n",
    "\n",
    "preprocessing is already completed and the preprocessed images are stored in the file path(/home/shree_xd/Documents/deepfake_detection/preprocessed) . do not give code for preprocessing. this preprocessed folder contain images stored as (fake_1.jpeg,fake_2.webp,................,real_1.png,real_2.jpeg.........)\n",
    "give code for \n",
    "Set up EfficientNet for feature extraction\n",
    "Patch Embedding and Vision Transformer\n",
    "Combine the features and build the final model\n",
    "model evaluation accuracy scores and roc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet-B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define EfficientNet-B7 model for feature extraction\n",
    "def build_efficientnet():\n",
    "    base_model = EfficientNetB7(weights='imagenet', include_top=False, input_shape=(384, 384, 3))\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Build the EfficientNet model\n",
    "efficientnet_model = build_efficientnet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patch Embedding and Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2767927898.py, line 90)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 90\u001b[0;36m\u001b[0m\n\u001b[0;31m    model.compile(loss\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Reshape, Dense\n",
    "from vit_keras import vit, utils\n",
    "\n",
    "# Patch size and embedding dimensions\n",
    "patch_size = 32\n",
    "embedding_dim = 1024\n",
    "\n",
    "# Input layer for patch embedding\n",
    "input_patch = Input(shape=(patch_size, patch_size, 3))\n",
    "reshaped_patch = Reshape((patch_size * patch_size, 3))(input_patch)\n",
    "\n",
    "# Vision Transformer (ViT) for patch embedding\n",
    "vit_model = vit.vit_b16(\n",
    "    image_size=patch_size,\n",
    "    activation='sigmoid',\n",
    "    pretrained=True,\n",
    "    include_top=False,\n",
    "    pretrained_top=False\n",
    ")(reshaped_patch)\n",
    "\n",
    "# Final dense layer for embedding\n",
    "embedding_output = Dense(embedding_dim)(vit_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine features and build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 2560), (None, 1024, 1024)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m features_fake \u001b[38;5;241m=\u001b[39m efficientnet_model(input_fake)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Concatenate EfficientNet features with ViT embeddings\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m combined_features_real \u001b[38;5;241m=\u001b[39m \u001b[43mConcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m combined_features_fake \u001b[38;5;241m=\u001b[39m Concatenate()([features_fake, embedding_output])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Final classification layers\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/merging/concatenate.py:85\u001b[0m, in \u001b[0;36mConcatenate.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     83\u001b[0m ranks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;28;01mfor\u001b[39;00m shape \u001b[38;5;129;01min\u001b[39;00m shape_set)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ranks) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Get the only rank for the set.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m (rank,) \u001b[38;5;241m=\u001b[39m ranks\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 2560), (None, 1024, 1024)]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Concatenate, Dropout\n",
    "\n",
    "# Inputs for real and fake images\n",
    "input_real = Input(shape=(384, 384, 3))\n",
    "input_fake = Input(shape=(384, 384, 3))\n",
    "\n",
    "# Obtain features from EfficientNet\n",
    "features_real = efficientnet_model(input_real)\n",
    "features_fake = efficientnet_model(input_fake)\n",
    "\n",
    "# Concatenate EfficientNet features with ViT embeddings\n",
    "combined_features_real = Concatenate()([features_real, embedding_output])\n",
    "combined_features_fake = Concatenate()([features_fake, embedding_output])\n",
    "\n",
    "# Final classification layers\n",
    "dense_real = Dense(1, activation='sigmoid')(combined_features_real)\n",
    "dense_fake = Dense(1, activation='sigmoid')(combined_features_fake)\n",
    "\n",
    "# Build the model\n",
    "model = Model(inputs=[input_real, input_fake], outputs=[dense_real, dense_fake])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=SGD(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Assuming you have paths to your preprocessed images and labels\n",
    "image_paths = [...]  # List of image file paths\n",
    "labels = [...]  # List of corresponding labels (0 for real, 1 for fake)\n",
    "\n",
    "# Load images and preprocess\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(384, 384))\n",
    "    img = img_to_array(img) / 255.0  # Normalize pixel values\n",
    "    return img\n",
    "\n",
    "# Load images and labels\n",
    "images = np.array([load_and_preprocess_image(path) for path in image_paths])\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Assuming you have a train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit([X_train, X_train], [y_train, y_train], epochs=40, batch_size=12, validation_split=0.2, callbacks=[EarlyStopping(patience=5)])\n",
    "\n",
    "# Evaluate on test data\n",
    "predictions = model.predict([X_test, X_test])\n",
    "predictions = np.concatenate(predictions, axis=1).flatten()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, np.round(predictions))\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"AUC: {roc_auc}\")\n",
    "\n",
    "# Plot ROC curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
